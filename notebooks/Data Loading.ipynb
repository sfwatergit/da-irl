{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "sys.path.append('../../da-irl')\n",
    "\n",
    "# Local\n",
    "from src.impl.activity_env import ActivityEnv\n",
    "from src.impl.activity_mdp import ATPTransition, ActivityMDP\n",
    "from src.impl.activity_params import MATSimParameters\n",
    "from src.impl.activity_rewards import ActivityRewardFunction\n",
    "from src.irl.meirl import MaxEntIRLAgent\n",
    "from src.misc.utils import create_dir_if_not_exists\n",
    "from src.file_io.trace_loader import TraceLoader\n",
    "\n",
    "# Vendor\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import Day\n",
    "import shapely\n",
    "from shapely.geometry import box\n",
    "import numpy as np\n",
    "import folium\n",
    "\n",
    "shapely.speedups.enable()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global magics statements\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BBOX:\n",
    "LAT_MIN=32.831\n",
    "LAT_MAX=38.67\n",
    "LNG_MIN=-128.9\n",
    "LNG_MAX=-117.41\n",
    "\n",
    "# DOW\n",
    "MON = 0\n",
    "TUES = 1\n",
    "WEDS = 2\n",
    "THUR = 3\n",
    "FRI = 4\n",
    "SAT = 5\n",
    "SUN = 6\n",
    "\n",
    "# Path\n",
    "PATH = '../../da-irl/data/traces/traces_persona_1.csv'\n",
    "\n",
    "def great_circle_distance(pt1,pt2):\n",
    "    \"\"\"\n",
    "    Return the great-circle distance in kilometers between two points,\n",
    "    defined by a tuple (lat, lon).\n",
    "    Examples\n",
    "    --------\n",
    "    >>> brussels = (50.8503, 4.3517)\n",
    "    >>> paris = (48.8566, 2.3522)\n",
    "    >>> great_circle_distance(brussels, paris)\n",
    "    263.9754164080347\n",
    "    \"\"\"\n",
    "    r = 6371.\n",
    "    \n",
    "    delta_latitude = np.radians(pt1[:,0] - pt2[:,0])\n",
    "    delta_longitude = np.radians(pt1[:,1] - pt2[:,1])\n",
    "    latitude1 = np.radians(pt1[:,0])\n",
    "    latitude2 = np.radians(pt2[:,0])\n",
    "\n",
    "    a = np.sin(delta_latitude / 2) ** 2 + np.cos(latitude1) * np.cos(latitude2) * np.sin(delta_longitude / 2) ** 2\n",
    "    return r * 2. * np.arcsin(np.sqrt(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import timedelta\n",
    "from geopy.distance import great_circle\n",
    "\"\"\"\n",
    "INPUTS:\n",
    "    df={o1,o2,...,on} Set of objects\n",
    "    spatial_threshold = Maximum geographical coordinate (spatial) distance value\n",
    "    temporal_threshold = Maximum non-spatial distance value\n",
    "    min_neighbors = Minimun number of points within Eps1 and Eps2 distance\n",
    "OUTPUT:\n",
    "    C = {c1,c2,...,ck} Set of clusters\n",
    "\"\"\"\n",
    "def ST_DBSCAN(df, spatial_threshold, temporal_threshold, min_neighbors):\n",
    "    cluster_label = 0\n",
    "    NOISE = -1\n",
    "    UNMARKED = 777777\n",
    "    stack = []\n",
    "\n",
    "    # initialize each point with unmarked\n",
    "    df['cluster'] = UNMARKED\n",
    "    \n",
    "    # for each point in database\n",
    "    for index, point in df.iterrows():\n",
    "        if df.loc[index]['cluster'] == UNMARKED:\n",
    "            neighborhood = retrieve_neighbors(index, df, spatial_threshold, temporal_threshold)\n",
    "            \n",
    "            if len(neighborhood) < min_neighbors:\n",
    "                df.set_value(index, 'cluster', NOISE)\n",
    "\n",
    "            else: # found a core point\n",
    "                cluster_label = cluster_label + 1\n",
    "                df.set_value(index, 'cluster', cluster_label)# assign a label to core point\n",
    "\n",
    "                for neig_index in neighborhood: # assign core's label to its neighborhood\n",
    "                    df.set_value(neig_index, 'cluster', cluster_label)\n",
    "                    stack.append(neig_index) # append neighborhood to stack\n",
    "                \n",
    "                while len(stack) > 0: # find new neighbors from core point neighborhood\n",
    "                    current_point_index = stack.pop()\n",
    "                    new_neighborhood = retrieve_neighbors(current_point_index, df, spatial_threshold, temporal_threshold)\n",
    "                    \n",
    "                    if len(new_neighborhood) >= min_neighbors: # current_point is a new core\n",
    "                        for neig_index in new_neighborhood:\n",
    "                            neig_cluster = df.loc[neig_index]['cluster']\n",
    "                            if (neig_cluster != NOISE) & (neig_cluster == UNMARKED): \n",
    "                                # TODO: verify cluster average before add new point\n",
    "                                df.set_value(neig_index, 'cluster', cluster_label)\n",
    "                                stack.append(neig_index)\n",
    "    return df\n",
    "\n",
    "\n",
    "def retrieve_neighbors(index_center, df, spatial_threshold, temporal_threshold):\n",
    "    neigborhood = []\n",
    "\n",
    "    center_point = df.loc[index_center]\n",
    "\n",
    "#     # filter by time \n",
    "#     min_time = center_point['start_time'] - timedelta(minutes = temporal_threshold)\n",
    "#     max_time = center_point['end_time'] + timedelta(minutes = temporal_threshold)\n",
    "#     df = df[(df['start_time'] >= min_time) & (df['end_time'] <= max_time)]\n",
    "    \n",
    "    # filter by distance\n",
    "    for index, point in df.iterrows():\n",
    "        if index != index_center:\n",
    "            distance = great_circle((center_point['lat'], center_point['lng']), (point['lat'], point['lng'])).meters\n",
    "            \n",
    "            if distance <= spatial_threshold:\n",
    "#                 print distance\n",
    "                neigborhood.append(index)\n",
    "\n",
    "    return neigborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class User:\n",
    "    def __init__(self,records_path):\n",
    "        self._records_path = records_path\n",
    "        self._records = None\n",
    "        \n",
    "        self.name = None\n",
    "        self.home = None\n",
    "        self.work = None\n",
    "        self.weekend_days = [SAT,SUN]  # hard code for now\n",
    "        self.work_start_hr = 13 # hard code for now\n",
    "        self.work_end_hr = 16 # hard code for now\n",
    "        self.early_morning_hr = 5\n",
    "        self.late_night_hr = 18\n",
    "        \n",
    "        \n",
    "        self.attributes = {}\n",
    "        self._load_records()\n",
    "    \n",
    "    def _load_records(self):\n",
    "        df = TraceLoader.load_traces_from_csv(self._records_path)\n",
    "        \n",
    "        df=self._process_home_work_other(df)\n",
    "        df=self._process_speed(df)\n",
    "        df=self._process_duration(df)\n",
    "        self._records=df\n",
    "        \n",
    "    def _process_home_work_other(self,df):\n",
    "        df['at_home']=0\n",
    "        df['at_work']=0\n",
    "        df['at_other']=0\n",
    "\n",
    "        for idx,row in df.iterrows():\n",
    "            tup = (row.enter_time.dayofweek, row.enter_time.hour, row.exit_time.dayofweek, row.exit_time.hour)\n",
    "            is_at_home = self._filter_home(tup)\n",
    "            is_at_work = self._filter_work(tup)\n",
    "            is_at_other = ((not is_at_home) & (not is_at_work))\n",
    "            df.loc[idx,'at_home'] = 1 if is_at_home else 0\n",
    "            df.loc[idx,'at_work'] = 1 if is_at_work else 0\n",
    "            df.loc[idx,'at_other'] = 1 if is_at_other else 0\n",
    "        df=df.dropna()\n",
    "        return df\n",
    "        \n",
    "    def _filter_home(self, tup):\n",
    "        enter_day,enter_hr,exit_day,exit_hr = tup\n",
    "        is_same_day = (enter_day==exit_day)\n",
    "        is_morning_hour = (exit_hr <= self.early_morning_hr)\n",
    "        is_consecutive_day = (((enter_day==SUN) & (exit_day==MON))|(enter_day + 1 == exit_day))\n",
    "        is_late_night = ((enter_hr >= self.late_night_hr)&is_morning_hour)\n",
    "        cond_1 = (is_consecutive_day & is_late_night)\n",
    "        cond_2 = (is_same_day & is_morning_hour)\n",
    "        return cond_1|cond_2\n",
    "    \n",
    "    def _filter_work(self, tup):\n",
    "        enter_day,enter_hr,exit_day,exit_hr = tup\n",
    "        is_work_hour = ((enter_hr>self.work_start_hr)&(exit_hr<self.work_end_hr))\n",
    "        is_work_day = (enter_day not in self.weekend_days)&(exit_day not in self.weekend_days)\n",
    "        is_same_day = (enter_day==exit_day)\n",
    "        return is_work_hour & (is_work_day & is_same_day)\n",
    "    \n",
    "    def _process_speed(self,df):\n",
    "        cons_pts = np.array(zip(zip(df.lat.values[0:],df.lng.values[0:]),zip(df.lat.values[1:],df.lng.values[1:])))\n",
    "        pts1=cons_pts[:,0]\n",
    "        pts2=cons_pts[:,1]\n",
    "        dist=np.round(great_circle_distance(pts1,pts2),5)\n",
    "        df['dist'] = np.hstack([[0],dist])\n",
    "        \n",
    "        enters=df.enter_time.dt.to_pydatetime()\n",
    "        exits=df.exit_time.dt.to_pydatetime()\n",
    "        time_diff = np.diff(zip(exits[0:],enters[1:]))\n",
    "        time_diff_s = np.apply_along_axis(lambda x: x[0].seconds,1, time_diff)\n",
    "        df['time_diff']=np.vstack([[0],time_diff])\n",
    "        df['speed'] = np.hstack([[0],np.round(dist/time_diff_s,5)])\n",
    "        return df\n",
    "    \n",
    "    def _process_duration(self,df):\n",
    "        df['duration']=df.exit_time-df.enter_time\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#         self._records = gpd.GeoDataFrame(df.drop(['lat', 'lng'], axis=1),\n",
    "#                                 crs={'init': 'epsg:4326'},\n",
    "#                                 geometry=[shapely.geometry.Point(xy) for xy in zip(df.lat, df.lng)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=User(PATH)._records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_day']=df.enter_time.dt.normalize()\n",
    "df['start_time']=df.enter_time.dt.floor('15min')\n",
    "df['end_time']=df.exit_time.dt.floor('15min')\n",
    "df['end_day'] = start_day + Day(1)- DateOffset(minutes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "idxs=[]\n",
    "for i,row in df.iterrows():\n",
    "    if row.end_day<row.end_time:\n",
    "        x.append(row)\n",
    "        idxs.append(i)\n",
    "df.drop(df.index[idxs],inplace=True)\n",
    "days=[]\n",
    "for row in x:\n",
    "    prev_day = row.copy()\n",
    "    next_day = row.copy()\n",
    "    next_day.end_time = prev_day.end_time\n",
    "    prev_day.end_time = prev_day.end_day\n",
    "    next_day.start_time = next_day.start_day\n",
    "    days.append(pd.concat([prev_day,next_day],1).T)\n",
    "df=df.append(pd.concat(days),ignore_index=True)\n",
    "df=df.sort_values(by='start_time')\n",
    "df=df.reindex(range(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.001, min_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster']=db.fit_predict(df[['lat','lng']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = df.copy()\n",
    "labels = df.cluster.values\n",
    "max_label = np.max(labels)\n",
    "for label in xrange(max_label + 1):\n",
    "    home_count = np.sum(activities.loc[labels == label, 'at_home'])\n",
    "    work_count = np.sum(activities.loc[labels == label, 'at_work'])\n",
    "\n",
    "    if (home_count == 0) and (work_count == 0):\n",
    "        continue\n",
    "    elif home_count > work_count:\n",
    "        activities.loc[(labels == label) & (activities.at_work != 1), 'at_home'] = 1\n",
    "    elif home_count < work_count:\n",
    "        activities.loc[(labels == label) & (activities.at_home != 1), 'at_work'] = 1\n",
    "\n",
    "activities.loc[(activities.at_home == 0) & (activities.at_work == 0), 'at_other'] = 1\n",
    "activities.loc[(activities.at_home==1)&(activities.at_other==1),'at_other']=0\n",
    "activities.loc[(activities.at_work==1)&(activities.at_other==1),'at_other']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf= gpd.GeoDataFrame(df.drop(['lat', 'lng'], axis=1),\n",
    "                                crs={'init': 'epsg:4326'},\n",
    "                                geometry=[shapely.geometry.Point(xy) for xy in zip(df.lat, df.lng)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_label(row):\n",
    "    if(row.at_home==1):\n",
    "        return 'h'\n",
    "    elif(row.at_work==1):\n",
    "        return 'w'\n",
    "    else:\n",
    "        return 's'\n",
    "\n",
    "def make_seg_series(start, end, label, freq='15min'):\n",
    "    dr = pd.date_range(start, end,freq=freq)\n",
    "    label_ser = np.array([label]*len(dr),dtype=object)\n",
    "    return pd.Series(label_ser,index=dr)\n",
    "    \n",
    "def segment_day(df):\n",
    "    segs = []\n",
    "    # starting day w/ travel\n",
    "    for idx,(day,row) in enumerate(df.iterrows()):\n",
    "        if idx==0:\n",
    "            start_time = row.start_day\n",
    "            label='h'\n",
    "        else:\n",
    "            start_time = end_time\n",
    "            label='car'\n",
    "        end_time = row.start_time\n",
    "        \n",
    "        segs.append(make_seg_series(start_time,end_time,label))\n",
    "        start_time = end_time\n",
    "        label = get_current_label(row)\n",
    "        \n",
    "        end_time = row.end_time\n",
    "        segs.append(make_seg_series(start_time, end_time, label))\n",
    "        \n",
    "        if (idx == len(df)) and (row.end_time<row.end_day):\n",
    "            label = 'car'\n",
    "            end_time = row.end_day\n",
    "            segs.append(make_seg_series(start_time, end_time, label))\n",
    "    return pd.concat(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segs = []\n",
    "df=activities.copy()\n",
    "for d,grp in df.groupby([df.start_day.dt.year,df.start_day.dt.month,df.start_day.dt.day,df.start_day.dt.dayofweek]):\n",
    "    if d[-1] not in [5,6]:\n",
    "        seg=np.array(segment_day(grp).values)[:96]\n",
    "        segs.append(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-790-39f52ca128ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'S16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence"
     ]
    }
   ],
   "source": [
    "traj=np.array(segs,dtype='S16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/traces/trajectories/p0',traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/sfeygin/current_code/python/da-irl/notebooks'"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['h', 'h', 'h', ..., 'h', 'h', 'h'],\n",
       "       ['h', 'h', 'h', ..., 'h', 'h', 'h'],\n",
       "       ['h', 'h', 'h', ..., 'car', 'car', 'car'],\n",
       "       ..., \n",
       "       ['h', 'h', 'h', ..., 'h', 'h', 'h'],\n",
       "       ['h', 'h', 'h', ..., 'h', 'h', 'h'],\n",
       "       ['h', 'h', 'h', ..., 'h', 'h', 'h']],\n",
       "      dtype='|S16')"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
